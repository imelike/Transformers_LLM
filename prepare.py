'''
**PART A:** Prepare a  Hugging Face Dataset from Data in CSV Format

- **TERMINALDEN CALISTIRILACAK**

- git config --global user.email "melikeakalan1@gmail.com"
- git config --global user.name "imelike"
- huggingface-cli login


- **VERI SETINI INDIRME**
a. kmuatlar覺 terminalden s覺ras覺yla 癟al覺t覺r

- cd input terminalden 癟al覺t覺r bunu
- kaggle datasets download -d savasy/multiclass-classification-data-for-turkish-tc3
- dir
- tar -xf multiclass-classification-data-for-turkish-tc32.zip
- del C:\ADEN\GITHUB-PROJECTS\Transformers_LLM\input\multiclass-classification-data-for-turkish-tc32.zip
-
- **Veri setini dataFrame'e d繹n羹t羹relim**
- data = pd.read_csv('ticaret-yorum.csv')
- pd.set_option('max_colwidth', 100)
- data.head(5)

'''
import os
import re
import pandas as pd
import tensorflow as tf

file_name = "ticaret-yorum.csv"
path = "C:\ADEN\GITHUB-PROJECTS\Transformers_LLM\input\\"

from datasets import load_dataset
reviews_dataset = load_dataset("csv", data_files= path+file_name)

reviews_dataset

reviews_dataset['train'][:2]

# t羹m veri seti shuffle yap覺l覺r
# ilk 4000 yorumla transfomerlar eitilecek(s羹re uzamas覺n diye)

reviews_sample = reviews_dataset["train"].shuffle(seed=42).select(range(4000))
reviews_sample

"""
 bu veri seti metin s覺n覺fland覺rma i癟in yap覺lm覺 o y羹zden category deikeni var
 ama biz bu verisetiyle dil modeli eitip, metin 羹retimi yapaca覺z
 bu deiken de laz覺m deil
"""
reviews_sample = reviews_sample.remove_columns('category')
reviews_sample


reviews_sample = reviews_sample.rename_column(
    original_column_name="text", new_column_name="review"
)
reviews_sample

def compute_review_length(example):
    return {"review_length": len(example["review"].split())}

reviews_sample = reviews_sample.map(compute_review_length)
# Inspect the first training example
reviews_sample[0]

reviews_sample.sort("review_length")[:3]

########## ONEMLI #################

# Duygu analizinde k覺sa c羹mleler de model i癟in etkili olur ama
# Dil modeli eitimini k繹t羹 etkileyebileceinden 30 dan az kelime i癟eren yorumlar silinir
# 250 yorum silindi

reviews_sample = reviews_sample.filter(lambda x: x["review_length"] > 30)
print(reviews_sample.num_rows)

reviews_sample[:3]

# Veriden bir sample ald覺覺m覺zda ..., Devam覺n覺 oku gibi tekrar eden anlams覺z tokenlar覺 siliyoruz
def remove_repeated(example):
    example["review"] = example["review"].replace('...', '')
    example["review"] = example["review"].replace(',"', '. ')
    example["review"] = example["review"].replace('!.', '.')
    example["review"] = example["review"].replace('!,', '. ')
    example["review"] = example["review"].replace('"', '')
    example["review"] = re.sub('([a-zA-Z0-9z覺羹繹癟Z襤]),([a-zA-Z0-9z覺羹繹癟Z襤])', '\\1. \\2', example["review"])

    return {"review": example["review"].replace('Devam覺n覺 oku', '')}


# review_sample'da bulunan her bir yoruma yukar覺daki ilem uygulan覺r

reviews_sample = reviews_sample.map(remove_repeated)
reviews_sample[:3]


###### VALIDATION SETI OLUSTURMA #########
# Veri setimizde uan sadece train var bunu train ve test olarak ay覺rmak istiyoruz
# ama model eitirken teste ihtiyac覺m yok validation'a ihtiyac覺m var
# test kolonunu validation olarak isimlendiriyorum

reviews_sample = reviews_sample.train_test_split(train_size=0.9, seed=42)
# Rename the default "test" split to "validation"
reviews_sample["validation"] = reviews_sample.pop("test")

# bu bir s繹zl羹k, bu s繹zl羹kte train ve val o.羹 iki ayr覺 dataset var
reviews_sample

for key in reviews_sample["train"][0]:
    print(f"{key.upper()}: {reviews_sample['train'][0][key]}")


# uan 羹zerinde Dil Modeli eiteceim veri setim haz覺r bunu Hugging Face Hub'a y羹kleyeceim
reviews_sample.push_to_hub("imelike/turkishReviews-ds-mini")

# Yukar覺da y羹kledim veri setini Hugging Face Hub'dan indireceim
downloaded_dataset = load_dataset("imelike/turkishReviews-ds-mini")
downloaded_dataset

